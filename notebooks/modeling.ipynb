{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import geemap\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, balanced_accuracy_score, balanced_accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import json\n",
    "from ipyleaflet import GeoJSON\n",
    "import os\n",
    "import pickle \n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_values = [0,1,2,3,4,5,6]\n",
    "class_palette = ['3388ff', 'e72a08', '3ba702', 'e4f406', '44ff00','c88d0e', 'bab7b0']\n",
    "labels = { 0:'water',\n",
    "         1:'bare_soil',\n",
    "         2:'forest',\n",
    "         3:'crop_annual',\n",
    "         4:'crop_perennial',\n",
    "         5:'pasture',\n",
    "         6:'urban'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/train\\train_test_data.pickle\n"
     ]
    }
   ],
   "source": [
    "training_data = None\n",
    "for file in glob('../data/train/*' ):\n",
    "    print(file)\n",
    "    with open(file, 'rb') as f:\n",
    "    # Pickle the 'data' dictionary using the highest protocol available.\n",
    "        if training_data is None:\n",
    "            training_data = pickle.load( f)\n",
    "        else:\n",
    "            training_data = training_data.merge(pickle.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96820"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.size().getInfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load external validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/test\\data_41705538_11759867_data2.pickle\n",
      "../data/test\\data_45088599_2096907_data2.pickle\n",
      "../data/test\\data_45639137_21235329_data2.pickle\n",
      "../data/test\\data_46789047_23699069_data2.pickle\n",
      "../data/test\\data_validation_41925184_11792395_data2.pickle\n",
      "../data/test\\data_validation_4649515_23511.pickle\n",
      "../data/test\\data_validation_46822354_23368611_data2.pickle\n"
     ]
    }
   ],
   "source": [
    "collection = None\n",
    "for file in glob('../data/test/*' ):\n",
    "    print(file)\n",
    "    with open(file, 'rb') as f:\n",
    "    # Pickle the 'data' dictionary using the highest protocol available.\n",
    "        if collection is None:\n",
    "            collection = pickle.load( f)\n",
    "        else:\n",
    "            collection = collection.merge(pickle.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "249567"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.size().getInfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create map object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Map = geemap.Map(center=[-15, -57] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adds a column of deterministic pseudorandom numbers. \n",
    "sample = training_data.randomColumn()\n",
    "\n",
    "split = 0.5\n",
    "\n",
    "training_set = sample.filter(ee.Filter.lt('random', split))\n",
    "validation_set = sample.filter(ee.Filter.gte('random', split))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose one model to run and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train a CART classifier with default parameters.\n",
    "classifier = ee.Classifier.smileCart().train(training_set.filter(ee.Filter.notNull(['landcover']) ), label, bands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Train a CART classifier with default parameters.\n",
    "classifier = ee.Classifier.smileGradientTreeBoost().train(training_set.filter(ee.Filter.notNull(['landcover']) ), label, bands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Train a CART classifier with default parameters.\n",
    "classifier = ee.Classifier.smileRandomForest().train(training_set.filter(ee.Filter.notNull(['landcover']) ), label, bands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the validation result table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_set = collection.filter(ee.Filter.notNull(['landcover']) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "validated = validation_set.classify(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating URL ...\n",
      "Downloading data from https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/tables/6125843418c3fb0b8a3796dbc965b49b-fa0d4d7faf1cc875f62b142637e50ea7:getFeatures\n",
      "Please wait ...\n",
      "Data downloaded to C:\\Users\\lucas.m.pontes\\OneDrive - EDITORA E DISTRIBUIDORA EDUCACIONAL S A\\Biblio\\Udacity\\ML Engineer\\satellite image classifier\\model\\test_CART_v1.csv\n"
     ]
    }
   ],
   "source": [
    "geemap.ee_to_csv(validated, 'test_result_CART.csv', verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load validation result as a pandas dataframe and calculate the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-3d43d0c6a7a5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model/test_CART_v1.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "#Remember to change the name of the file\n",
    "val = pd.read_csv('model/test_CART.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(val['landcover'], val['classification'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_accuracy_score(val['landcover'], val['classification'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(val['landcover'], val['classification'], average = 'weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[97172,     0,     0,     0,     0,     0,     0],\n",
       "       [    0,  4900,   188,  1103,     1,  1871,   169],\n",
       "       [    4,     0, 43360,  3222,    41,     3,     0],\n",
       "       [    0,     3,   484,   808,     0,   754,    49],\n",
       "       [    0,     0, 13047,   119,     5,     0,     0],\n",
       "       [    0,     0,  8704, 16277,     8, 11950,     0],\n",
       "       [  372,  2646,    17,   845,    11,    57, 41377]], dtype=int64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(val['landcover'], val['classification'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val['label'] = val.landcover.map(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val.label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat = confusion_matrix(val['landcover'], val['classification'])\n",
    "fig, ax = plt.subplots(figsize=(8,8)) \n",
    "sns.heatmap(conf_mat, annot=True, fmt='d')\n",
    "bottom, top = ax.get_ylim()\n",
    "ax.set_ylim(bottom + 0.5, top - 0.5)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drawn a polygon over the map below you wish to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49faab567526441c9a78f9a47eae1088",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[40, -100], controls=(WidgetControl(options=['position'], widget=HBox(children=(ToggleButton(value=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = (ee.ImageCollection('COPERNICUS/S2_SR')\n",
    "                     .filterBounds(Map.user_rois.geometry())\n",
    "                     .filterDate('2019-09-01', '2019-12-31')\n",
    "                     .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE',10))\n",
    "                     .median().clip(Map.user_rois.geometry())\n",
    "                     )\n",
    "\n",
    "            # Add the image layer to the map and display it.\n",
    "            Map.add_ee_layer(\n",
    "                image, {'bands': ['B4', 'B3', 'B2'],\n",
    "                        'min': 0, 'max': 2000}, 'sentinel')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify the image with the same bands used for training.\n",
    "result = image.select(bands).classify(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "landcover = result.set('classification_class_values', class_values )\n",
    "landcover = landcover.set('classification_class_palette', class_palette )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56670b60ef0e48da9a8a5652cc3d264a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(bottom=146194.0, center=[-19.93978728199503, -51.097412109375], controls=(WidgetControl(options=['position…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "legend_dict = {\n",
    "    'Water': '3388ff',\n",
    "    'Bare soil': 'e72a08',\n",
    "    'Forest': '3ba702',\n",
    "    'Annual crop': 'e4f406',\n",
    "    'Perennial crop': '44ff00',\n",
    "    'Pasture': 'c88d0e',\n",
    "    'Urban area': 'bab7b0'\n",
    "}\n",
    "\n",
    "Map.addLayer(landcover, {}, 'classified')\n",
    "Map.add_legend(legend_dict=legend_dict) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save fitted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('trained_model.pickle', 'wb') as f:\n",
    "    # Pickle the 'data' dictionary using the highest protocol available.\n",
    "    pickle.dump(classifier, f)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
